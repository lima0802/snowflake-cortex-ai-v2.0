{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd44cce2",
   "metadata": {},
   "source": [
    "# üöÄ Cortex Analyst Interactive Tutorial\n",
    "## Learn by Doing: Snowflake Cortex Analyst Service\n",
    "\n",
    "**Author:** Li Ma  \n",
    "**Date:** February 24, 2026  \n",
    "**Project:** DIA v2.0 - Direct Marketing Analytics Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "This interactive notebook teaches you how to:\n",
    "1. ‚úÖ Connect to Snowflake with Python\n",
    "2. ‚úÖ Use Cortex Analyst to convert natural language to SQL\n",
    "3. ‚úÖ Execute queries and process results\n",
    "4. ‚úÖ Build production-ready service wrappers\n",
    "5. ‚úÖ Handle errors and log activities\n",
    "\n",
    "## üéØ Prerequisites\n",
    "\n",
    "- Docker containers running (`docker-compose up`)\n",
    "- Snowflake credentials configured in `.env` file\n",
    "- Semantic model deployed to Snowflake stage\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** Run each cell with `Shift + Enter` and experiment with the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aabc8444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing required packages...\n",
      "   Installing structlog...\n",
      "   ‚úÖ structlog installed\n",
      "   Installing python-dotenv...\n",
      "   ‚úÖ python-dotenv installed\n",
      "   Installing snowflake-snowpark-python...\n",
      "   ‚úÖ snowflake-snowpark-python installed\n",
      "\n",
      "‚úÖ Installation complete!\n",
      "‚ö†Ô∏è  If this is the first install, please RESTART THE KERNEL:\n",
      "   Jupyter menu: Kernel ‚Üí Restart Kernel\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for this notebook\n",
    "# Run this cell once to install dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'structlog',\n",
    "    'python-dotenv',\n",
    "    'snowflake-snowpark-python'\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "for package in packages:\n",
    "    print(f\"   Installing {package}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"   ‚úÖ {package} installed\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Failed to install {package}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n",
    "print(\"‚ö†Ô∏è  If this is the first install, please RESTART THE KERNEL:\")\n",
    "print(\"   Jupyter menu: Kernel ‚Üí Restart Kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1052625",
   "metadata": {},
   "source": [
    "## üì¶ Step 0: Install Dependencies (Run Once)\n",
    "\n",
    "**Important:** Run this cell first to install required packages in your Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a37ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "   Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to path so we can import modules\n",
    "import sys\n",
    "sys.path.insert(0, '/app')  # For Docker environment\n",
    "\n",
    "# Core Python libraries\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Snowflake libraries\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Environment and logging\n",
    "from dotenv import load_dotenv\n",
    "from utils.logging import get_logger\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"   Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45a492cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AnalystResponse dataclass\n",
    "@dataclass\n",
    "class AnalystResponse:\n",
    "    \"\"\"\n",
    "    Structured response from Cortex Analyst.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5efd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AnalystResponse dataclass defined successfully!\n",
      "   Query: What is the average open rate?\n",
      "   SQL: SELECT AVG(open_rate) FROM email_campaigns\n",
      "   Results: [{'AVG(open_rate)': 22.5}]\n",
      "   Metadata: {'row_count': 1}\n",
      "   Error: None\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class AnalystResponse:\n",
    "    \"\"\"\n",
    "    Container for Cortex Analyst responses.\n",
    "    \n",
    "    Attributes:\n",
    "        query (str): The natural language question\n",
    "        sql (str): Generated SQL query\n",
    "        results (List[Dict]): Query results as list of dictionaries\n",
    "        metadata (Dict): Additional information (row count, execution time)\n",
    "        error (str): Error message if something went wrong\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    sql: Optional[str] = None\n",
    "    results: Optional[List[Dict[str, Any]]] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary (useful for JSON APIs)\"\"\"\n",
    "        return {\n",
    "            \"query\": self.query,\n",
    "            \"sql\": self.sql,\n",
    "            \"results\": self.results,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"error\": self.error\n",
    "        }\n",
    "    \n",
    "# Test it out!\n",
    "sample_reponse = AnalystResponse(\n",
    "    query=\"What is the average open rate?\",\n",
    "    sql=\"SELECT AVG(open_rate) FROM email_campaigns\",\n",
    "    results=[{\"AVG(open_rate)\": 22.5}],\n",
    "    metadata={\"row_count\":1}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AnalystResponse dataclass defined successfully!\")\n",
    "print(f\"   Query: {sample_reponse.query}\")\n",
    "print(f\"   SQL: {sample_reponse.sql}\")\n",
    "print(f\"   Results: {sample_reponse.results}\")\n",
    "print(f\"   Metadata: {sample_reponse.metadata}\")\n",
    "print(f\"   Error: {sample_reponse.error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8967f84c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2769104461.py, line 217)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# MAIN SERVICE CLASS FOR CORTEX ANALYST\n",
    "class CortexAnalyst:\n",
    "    \"\"\"\n",
    "    Python wrapper for Snowflake Cortex Analyst service.\n",
    "\n",
    "    This class handles all interactions with Cortex Analyst:\n",
    "    - Connecting to Snowflake\n",
    "    - Sending natural language questions\n",
    "    - Receiving SQL and results\n",
    "    - Error handling and logging\n",
    "\n",
    "    Usage Example:\n",
    "      # Create an instance\n",
    "      analyst = CortexAnalyst()\n",
    "\n",
    "      # Ask a question\n",
    "      response = analyst.send_message(\"What was the average open rate last week?\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        semantic_model_file: str = \"semnatic.yaml\",\n",
    "        stage_name: str = \"SEMANTIC_MODELS\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the CortexAnalyst instance.\n",
    "\n",
    "        Args:\n",
    "            semantic_model_file (str): Name of the semantic model file in Snowflake stage.\n",
    "            stage_name (str): Name of the Snowflake stage where the semantic model is stored.\n",
    "\n",
    "        What happens here:\n",
    "        1. Load configuration from environment variables (.env file)\n",
    "        2. Create a connection session to Snowflake\n",
    "        3. Prepares the path to the semantic model\n",
    "        \"\"\"\n",
    "\n",
    "        # Store configuration\n",
    "        self.semantic_model_file = semantic_model_file\n",
    "        self.stage_name = stage_name\n",
    "\n",
    "        # Get Snowflake credentials from environment variables\n",
    "        # These were set in the .env file and loaded by load_dotenv()\n",
    "        self.account = os.getenv(\"SNOWFLAKE_ACCOUNT\")\n",
    "        self.user = os.getenv(\"SNOWFLAKE_USER\")\n",
    "        self.password = os.getenv(\"SNOWFLAKE_PASSWORD\")\n",
    "        self.database = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
    "        self.schema = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    "        self.warehouse = os.getenv(\"SNOWFLAKE_WAREHOUSE\")\n",
    "        self.role = os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "\n",
    "        # Initialize Snowflake session (connection will be creaed on demand)\n",
    "        self.session: Optional[Session] = None\n",
    "\n",
    "        # Log the initialization\n",
    "        logger.info(\"CortexAnalyst initialized'\",\n",
    "                    database = self.database,\n",
    "                    schema = self.schema,\n",
    "                    semantic_model_file = f\"@{stage_name}/{semantic_model_file}\"\n",
    "        )\n",
    "\n",
    "    # CONNECTION MANAGEMENT\n",
    "    def _get_session(self) -> Session:\n",
    "        \"\"\"\n",
    "        Get or create a Snowflake session (lazy loading pattern).\n",
    "        \n",
    "        Why \"lazy loading\"?\n",
    "        Instead of connecting immediately when we create the CortexAnalyst object,\n",
    "        we wait until we actually need the connection. This saves resources!\n",
    "        \n",
    "        Returns:\n",
    "            Session: Active Snowflake session\n",
    "        \n",
    "        Raises:\n",
    "            Exception: If connection fails\n",
    "        \"\"\"\n",
    "        # If we alreay have a session, reuse it. Otherwise, create a new one.\n",
    "        if self.session is None:\n",
    "            return self._session\n",
    "        \n",
    "        try:\n",
    "            #create connection parmeters dictionary\n",
    "            connection_params = {\n",
    "                \"account\": self.account,\n",
    "                \"user\": self.user,\n",
    "                \"password\": self.password,  \n",
    "                \"database\": self.database,\n",
    "                \"schema\": self.schema,\n",
    "                \"warehouse\": self.warehouse,\n",
    "                \"role\": self.role\n",
    "            }\n",
    "\n",
    "            # create the session (connect to Snowflake)\n",
    "            logger.info(\"Creating new Snowflake session...\")\n",
    "            self._session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "            logger.info(\n",
    "                \"Snowflake session created successfully!\",\n",
    "                account=self.account,\n",
    "                database=self.database\n",
    "            )\n",
    "\n",
    "            return self._session\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create Snowflake session: {e}\")\n",
    "            raise Exception(f\"Snowflake connection error: {e}\")\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the Snowflake session if it exists.\n",
    "        \n",
    "        Always call this when you're done to free up resources. \n",
    "        Good practice: Use \"with\" statement or try/finally block.\n",
    "\n",
    "        Example:\n",
    "            analyst = CortexAnalyst()\n",
    "            try:\n",
    "                response = analyst.send_message(\"What is the total sales?\")\n",
    "            finally:\n",
    "                analyst.close()   # Always cleanup!\n",
    "        \"\"\"\n",
    "\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "            self._session = None\n",
    "            logger.info(\"Snowflake session closed.\")\n",
    "\n",
    "\n",
    "    def send_message(\n",
    "        self,\n",
    "        query: str,\n",
    "        conversation_id: Optional[str] = None\n",
    "    ) -> AnalystResponse:\n",
    "        \"\"\"\n",
    "        Send a natural language question to Cortex Analyst.\n",
    "        \n",
    "        This is the main method you'll use! It:\n",
    "        1. Takes your natural language question\n",
    "        2. Sends it to Cortex Analyst\n",
    "        3. Gets back SQL and executes it\n",
    "        4. Returns the results in a nice format\n",
    "        \n",
    "        Args:\n",
    "            query (str): Your natural language question\n",
    "                Examples:\n",
    "                - \"What was the average open rate last month?\"\n",
    "                - \"Show me click rates by market\"\n",
    "                - \"Which campaigns had bounce rate above 5%?\"\n",
    "            \n",
    "            conversation_id (Optional[str]): ID for multi-turn conversations\n",
    "                (useful for follow-up questions - Cortex remembers context!)\n",
    "        \n",
    "        Returns:\n",
    "            AnalystResponse: Contains SQL, results, and metadata\n",
    "        \n",
    "        Example:\n",
    "            analyst = CortexAnalyst()\n",
    "            \n",
    "            # Ask a question\n",
    "            response = analyst.send_message(\n",
    "                \"What was total emails sent in January 2026?\"\n",
    "            )\n",
    "            \n",
    "            # Check if successful\n",
    "            if response.error:\n",
    "                print(f\"Error: {response.error}\")\n",
    "            else:\n",
    "                print(f\"SQL Generated: {response.sql}\")\n",
    "                print(f\"Results: {response.results}\")\n",
    "        \"\"\"\n",
    "        # Log the incoming query\n",
    "        logger.info(\"Received query\", query=query, conversation_id=conversation_id)\n",
    "\n",
    "        try:\n",
    "            # Get Snowflake session\n",
    "            session = self._get_session()\n",
    "\n",
    "            # Build the semantic model reference\n",
    "            # Format: @DATABASE.SCHEMA.STAGE_NAME/file.yaml\n",
    "            semantic_model_ref = (\n",
    "                f\"@{self.database}.{self.schema}.{self.stage_name}/\"\n",
    "                f\"{self.semantic_model_file}\"\n",
    "            )\n",
    "\n",
    "            # CORTEX ANALYST API CALL\n",
    "            # This is where we interact with the Cortex Analyst service.\n",
    "            # \n",
    "            # SNOWFLAKE.CORTEX.ANALYST() function:\n",
    "            # - First parameter: Your question (natural language)\n",
    "            # - Second parameter: Path to semantic model\n",
    "            # - Third parameter (optional): Conversation ID for context\n",
    "\n",
    "            if conversation_id:\n",
    "                # Multi-turn conversation (remembers previous interactions)\n",
    "                                # Multi-turn conversation (remembers previous questions)\n",
    "                sql_query = f\"\"\"\n",
    "                    SELECT SNOWFLAKE.CORTEX.ANALYST(\n",
    "                        '{self._escape_quotes(query)}',\n",
    "                        '{semantic_model_ref}',\n",
    "                        '{conversation_id}'\n",
    "                    ) AS response\n",
    "                \"\"\"\n",
    "            else:\n",
    "                # Single-turn question (no context)\n",
    "                sql_query = f\"\"\"\n",
    "                    SELECT SNOWFLAKE.CORTEX.ANALYST(\n",
    "                        '{self._escape_quotes(query)}',\n",
    "                        '{semantic_model_ref}'\n",
    "                    ) AS response\n",
    "                \"\"\"\n",
    "            logger.debug(\"Executing Cortex Analyst query\", sql=sql_query)\n",
    "\n",
    "            # Execute the query\n",
    "            result = session.sql(sql_query).collect()\n",
    "\n",
    "            # Parse the response from Cortex Analyst\n",
    "            # The result comes back as JSON, so we need to parse it\n",
    "            if result and len(result) > 0:\n",
    "                response_json = result[0]['RESPONSE']\n",
    "\n",
    "                # Convert from JSON string to Python dict\n",
    "                if isinstance(response_json, str):\n",
    "                    response_data = json.loads(response_json)\n",
    "                else:\n",
    "                    response_data = response_json  # Already a dict\n",
    "                \n",
    "                logger.debug(\"Parsed Cortex Analyst response\", response=response_data)\n",
    "\n",
    "                # Extract the components from the response\n",
    "                # Cortex Analyst returns: SQL query, results, and metadata\n",
    "                generated_sql = response_data.get(\"sql\", None)\n",
    "                query_results = response_data.get(\"results\", [])\n",
    "                metadata =  response_data.get(\"metadata\", {})\n",
    "                \n",
    "                # If SQL was generated, we can execute it to get fresh results\n",
    "                # (or use the results that Cortex already executed for us)\n",
    "                if generated_sql and not query_results:\n",
    "                    logger.info(\"Executing generated SQL\", sql=generated_sql)\n",
    "                    query_results = self._execute_sql(generated_sql)\n",
    "                \n",
    "                # Create successful response\n",
    "                response = AnalystResponse(\n",
    "                    query=query,\n",
    "                    sql=generated_sql,\n",
    "                    results=query_results,\n",
    "                    metadata=metadata or {\"row_count\": len(query_results)}\n",
    "                )\n",
    "\n",
    "                logger.info(\n",
    "                    \"Query processed successfully\",\n",
    "                    query=query,\n",
    "                    row_count=len(query_results) if query_results else 0\n",
    "                )\n",
    "                return response\n",
    "            \n",
    "            else:\n",
    "                # No results returned - something went wrong\n",
    "                error_msg = \"No results returned from Cortex Analyst.\"\n",
    "                logger.warning(error_msg, query=query)\n",
    "                \n",
    "                return AnalystResponse(\n",
    "                    query=query,\n",
    "                    error=error_msg\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any errors that occurred\n",
    "            error_msg = f\"Error processing query: {str(e)}\"\n",
    "            logger.error(error_msg, query=query, exception=str(e))\n",
    "\n",
    "            return AnalystResponse(\n",
    "                query=query,\n",
    "                error=error_msg\n",
    "            )\n",
    "\n",
    "# HELPER METHODS\n",
    "\n",
    "    def _escape_quotes(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Escape single quotes in text for SQL injection safety.\n",
    "        \n",
    "        Why is this important?\n",
    "        If a user asks: \"Show me John's campaigns\"\n",
    "        We need to escape the apostrophe so SQL doesn't break:\n",
    "        \"Show me John''s campaigns\" (double quote in SQL)\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text that might contain quotes\n",
    "        \n",
    "        Returns:\n",
    "            str: Text with quotes properly escaped\n",
    "        \"\"\"\n",
    "        return text.replace(\"'\", \"''\")\n",
    "    \n",
    "    def _execute_sql(self, sql: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Execute a SQL query and return results as list of dictionaries.\n",
    "        \n",
    "        This is useful when you have a SQL query and want to run it\n",
    "        against your Snowflake database.\n",
    "        \n",
    "        Args:\n",
    "            sql (str): The SQL query to execute\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: Results as list of row dictionaries\n",
    "        \n",
    "        Example Result:\n",
    "            [\n",
    "                {\"MARKET\": \"UK\", \"OPEN_RATE\": 22.5},\n",
    "                {\"MARKET\": \"Germany\", \"OPEN_RATE\": 19.8}\n",
    "            ]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            session = self._get_session()\n",
    "            # Execute the query\n",
    "            result = session.sql(sql).collect()\n",
    "\n",
    "            # Convert Snowflake Row objects to dictionaries\n",
    "            results_as_dicts = [row.asDict() for row in result]\n",
    "\n",
    "            logger.debug(\"SQL executed successfully\", sql=sql, row_count=len(results_as_dicts))\n",
    "            return results_as_dicts\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error executing SQL: {e}\", sql=sql)\n",
    "            raise Exception(f\"SQL execution error: {e}\")\n",
    "    \n",
    "    def verify_semantic_model(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Verify that the semantic model file exists in the Snowflake stage.\n",
    "        \n",
    "        This is a useful diagnostic method to check your setup!\n",
    "        Call this if you're having issues to verify everything is configured correctly.\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, Any]: Information about the semantic model file existence and details\n",
    "        \n",
    "        Returns:\n",
    "            Dict with verification results:\n",
    "            {\n",
    "                \"exists\": True/False,\n",
    "                \"file_name\": \"semantic.yaml\",\n",
    "                \"stage_path\": \"@DATABASE.SCHEMA.STAGE\",\n",
    "                \"file_size\": 12345,\n",
    "                \"last_modified\": \"2026-02-22...\"\n",
    "            }\n",
    "        \n",
    "        Example:\n",
    "            analyst = CortexAnalyst()\n",
    "            verification = analyst.verify_semantic_model()\n",
    "        \n",
    "            if verification[\"exists\"]:\n",
    "                print(\"Semantic model file found!\")      \n",
    "            else:\n",
    "                print(\"Semantic model file NOT found. Please check your stage and file name.\")\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            session = self._get_session()\n",
    "\n",
    "            # List files in the stage\n",
    "            stage_path = f\"@{self.database}.{self.schema}.{self.stage_name}\"\n",
    "            list_path = f\"{stage_path}\"\n",
    "\n",
    "            # Check if the file exists in the stage\n",
    "            sql_check = f\"LIST {file_path}\"\n",
    "            result = session.sql(sql_check).collect()\n",
    "\n",
    "            logger.info(\"Semantic model file found\", file_info=file_info)\n",
    "            \n",
    "            result = session.sql(list_sql).collect()\n",
    "\n",
    "            # Look for our semantic model file\n",
    "            for row in result:\n",
    "                file_name = row['name']\n",
    "                if self.semantic_model_file in file_name:\n",
    "                    verification = {\n",
    "                        \"exists\": True,\n",
    "                        \"file_name\": row['name'],\n",
    "                        \"stage_path\": stage_path,\n",
    "                        \"file_size\": row['size'],\n",
    "                        \"last_modified\": row['last_modified']\n",
    "                    }\n",
    "                    logger.info(\"Semantic model file found\", file_info=file_info)\n",
    "                    return verification\n",
    "            \n",
    "            #File not found\n",
    "            logger.warning(\n",
    "                \"Semantic model file NOT found in stage\", \n",
    "                stage_path=stage_path, \n",
    "                expected_file=self.semantic_model_file\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"exists\": False,\n",
    "                \"file_name\": self.semantic_model_file,\n",
    "                \"stage_path\": stage_path,\n",
    "                \"file_size\": None,\n",
    "                \"last_modified\": None\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to verify semantic model: {e}\")\n",
    "            return {\n",
    "                \"exists\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    # CONTEXT MANAGER SUPPORT (FOR \"WITH\" STATEMENT)\n",
    "    def __enter__(self):\n",
    "    \"\"\"Enable use with 'with' statement (context manager)\"\"\"\n",
    "    return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Automatically close connection when exiting 'with' block\"\"\"\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CortexAnalyst service\n",
    "from services.cortex_analyst import CortexAnalyst\n",
    "\n",
    "print(\"‚úÖ CortexAnalyst class imported successfully!\")\n",
    "print(\"   You can now create instances: analyst = CortexAnalyst()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9febdf",
   "metadata": {},
   "source": [
    "## üéì Summary: What You Learned\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "‚úÖ **Python OOP Concepts**\n",
    "- Classes and objects  \n",
    "- Instance methods and attributes\n",
    "- Context managers (`with` statement)\n",
    "- Type hints and dataclasses\n",
    "\n",
    "‚úÖ **Snowflake Integration**\n",
    "- Connecting with Snowpark\n",
    "- Executing SQL queries\n",
    "- Handling results\n",
    "\n",
    "‚úÖ **Service Design Patterns**\n",
    "- Lazy loading (efficient resource usage)\n",
    "- Error handling and logging\n",
    "- Structured responses\n",
    "\n",
    "‚úÖ **Production Best Practices**\n",
    "- Environment-based configuration\n",
    "- Comprehensive logging\n",
    "- Clean code with documentation\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Practice More**: Try different questions in the exercise cell above  \n",
    "2. **Build Other Services**: Apply this pattern to `cortex_complete.py`, `cortex_search.py`\n",
    "3. **Enhance Features**: Add caching, retry logic, rate limiting\n",
    "4. **Integration**: Use in your FastAPI endpoints\n",
    "5. **Testing**: Write pytest tests for edge cases\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex)\n",
    "- [CORTEX_ANALYST_LEARNING_GUIDE.md](../orchestrator/services/CORTEX_ANALYST_LEARNING_GUIDE.md)\n",
    "- [Python Dataclasses](https://docs.python.org/3/library/dataclasses.html)\n",
    "- [Structlog](https://www.structlog.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! üéâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d189af6",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise: Ask Your Own Question\n",
    "\n",
    "**Your Turn!** Try asking different questions about your email data.\n",
    "\n",
    "**Example Questions:**\n",
    "- \"What was the total emails sent last month?\"\n",
    "- \"Show me click rate by market\"\n",
    "- \"Which campaigns had bounce rate above 5%?\"\n",
    "- \"What is the average open rate by business unit?\"\n",
    "\n",
    "**Instructions:**\n",
    "1. Change the `my_question` variable below\n",
    "2. Run the cell\n",
    "3. See if Cortex Analyst can answer it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c660963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèãÔ∏è Exercise: Write your own question!\n",
    "\n",
    "with CortexAnalyst() as analyst:\n",
    "    # TODO: Change this question to something you want to know!\n",
    "    my_question = \"CHANGE THIS TO YOUR QUESTION\"\n",
    "    \n",
    "    response = analyst.send_message(my_question)\n",
    "    \n",
    "    if response.error:\n",
    "        print(f\"‚ùå Error: {response.error}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Question: {response.query}\")\n",
    "        print(f\"\\nüìä SQL: {response.sql}\")\n",
    "        print(f\"\\nüìà Results:\")\n",
    "        for i, row in enumerate(response.results[:10], 1):\n",
    "            print(f\"   {i}. {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cd727",
   "metadata": {},
   "source": [
    "## üß™ Test 3: Try Cortex Analyst (Natural Language Query)\n",
    "\n",
    "Now let's try asking a question in natural language!\n",
    "\n",
    "**Note:** This requires Cortex Analyst to be enabled in your Snowflake account. If not enabled yet, you'll see an error message (that's expected!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CortexAnalyst() as analyst:\n",
    "    # Ask a question in natural language\n",
    "    question = \"What is the average open rate?\"\n",
    "    \n",
    "    print(f\"ü§î Asking: '{question}'\")\n",
    "    print(\"   Processing...\")\n",
    "    \n",
    "    response = analyst.send_message(question)\n",
    "    \n",
    "    if response.error:\n",
    "        print(f\"\\n‚ö†Ô∏è  Query Failed (Expected if Cortex Analyst not enabled)\")\n",
    "        print(f\"   Error: {response.error}\")\n",
    "        print(\"\\nüí° To enable Cortex Analyst:\")\n",
    "        print(\"   1. Contact Snowflake support or your account admin\")\n",
    "        print(\"   2. Request 'Cortex Analyst' feature activation\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Query Successful!\")\n",
    "        print(f\"\\nüìù Question: {response.query}\")\n",
    "        print(f\"\\nüîç Generated SQL:\")\n",
    "        print(f\"   {response.sql}\")\n",
    "        print(f\"\\nüìä Results:\")\n",
    "        for i, row in enumerate(response.results[:5], 1):  # First 5 rows\n",
    "            print(f\"   {i}. {row}\")\n",
    "        print(f\"\\n‚ÑπÔ∏è  Metadata: {response.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb435902",
   "metadata": {},
   "source": [
    "## üß™ Test 2: Execute Simple SQL Query\n",
    "\n",
    "Before trying Cortex Analyst, let's test basic SQL execution against your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CortexAnalyst() as analyst:\n",
    "    try:\n",
    "        # Simple count query\n",
    "        sql = \"SELECT COUNT(*) AS ROW_COUNT FROM VW_SFMC_EMAIL_PERFORMANCE LIMIT 1\"\n",
    "        results = analyst._execute_sql(sql)\n",
    "        \n",
    "        print(\"‚úÖ SQL Execution Test Passed!\")\n",
    "        print(f\"   Rows in VW_SFMC_EMAIL_PERFORMANCE: {results[0]['ROW_COUNT']:,}\")\n",
    "        \n",
    "        # Get sample data\n",
    "        sample_sql = \"SELECT MARKET, OPEN_RATE, CLICK_RATE FROM VW_SFMC_EMAIL_PERFORMANCE LIMIT 5\"\n",
    "        sample_data = analyst._execute_sql(sample_sql)\n",
    "        \n",
    "        print(\"\\nüìä Sample Data:\")\n",
    "        for i, row in enumerate(sample_data, 1):\n",
    "            print(f\"   {i}. Market: {row['MARKET']}, Open Rate: {row['OPEN_RATE']}%, Click Rate: {row['CLICK_RATE']}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SQL Execution Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8631f64",
   "metadata": {},
   "source": [
    "## üß™ Test 1: Verify Semantic Model\n",
    "\n",
    "Let's verify your semantic model is deployed correctly in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analyst instance\n",
    "with CortexAnalyst() as analyst:\n",
    "    is_valid = analyst.verify_semantic_model()\n",
    "    \n",
    "    if is_valid:\n",
    "        print(\"‚úÖ Semantic Model Found!\")\n",
    "        print(\"   Your semantic model is deployed and ready to use.\")\n",
    "    else:\n",
    "        print(\"‚ùå Semantic Model Not Found\")\n",
    "        print(\"   Please deploy your semantic model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f1e7c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ CortexAnalyst Class: Complete Implementation\n",
    "\n",
    "Now let's import the complete CortexAnalyst class from our service module.\n",
    "\n",
    "This class includes:\n",
    "- Snowflake connection management\n",
    "- Cortex Analyst API calls\n",
    "- Error handling and logging\n",
    "- Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7b2f5",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Data Models: AnalystResponse\n",
    "\n",
    "Before we build the service, let's create a data structure to hold responses from Cortex Analyst.\n",
    "\n",
    "**Why dataclasses?**\n",
    "- Clean, readable code\n",
    "- Type hints for better error checking\n",
    "- Built-in methods like `__repr__`\n",
    "- Less boilerplate than regular classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaaf67",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries\n",
    "\n",
    "First, we need to import all the Python libraries we'll use:\n",
    "- **snowflake.snowpark**: For connecting to Snowflake\n",
    "- **dotenv**: For loading environment variables\n",
    "- **dataclasses**: For creating data structures\n",
    "- **json**: For parsing JSON responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
