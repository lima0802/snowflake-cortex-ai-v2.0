{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd44cce2",
   "metadata": {},
   "source": [
    "# üöÄ Cortex Analyst Interactive Tutorial\n",
    "## Learn by Doing: Snowflake Cortex Analyst Service\n",
    "\n",
    "**Author:** Li Ma  \n",
    "**Date:** February 24, 2026  \n",
    "**Project:** DIA v2.0 - Direct Marketing Analytics Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "This interactive notebook teaches you how to:\n",
    "1. ‚úÖ Connect to Snowflake with Python\n",
    "2. ‚úÖ Use Cortex Analyst to convert natural language to SQL\n",
    "3. ‚úÖ Execute queries and process results\n",
    "4. ‚úÖ Build production-ready service wrappers\n",
    "5. ‚úÖ Handle errors and log activities\n",
    "\n",
    "## üéØ Prerequisites\n",
    "\n",
    "- Docker containers running (`docker-compose up`)\n",
    "- Snowflake credentials configured in `.env` file\n",
    "- Semantic model deployed to Snowflake stage\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** Run each cell with `Shift + Enter` and experiment with the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d60b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing required packages...\n",
      "   Installing structlog...\n",
      "   ‚úÖ structlog installed\n",
      "   Installing python-dotenv...\n",
      "   ‚úÖ python-dotenv installed\n",
      "   Installing snowflake-snowpark-python...\n",
      "   ‚úÖ snowflake-snowpark-python installed\n",
      "\n",
      "‚úÖ Installation complete!\n",
      "‚ö†Ô∏è  If this is the first install, please RESTART THE KERNEL:\n",
      "   Jupyter menu: Kernel ‚Üí Restart Kernel\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for this notebook\n",
    "# Run this cell once to install dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'structlog',\n",
    "    'python-dotenv',\n",
    "    'snowflake-snowpark-python'\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "for package in packages:\n",
    "    print(f\"   Installing {package}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"   ‚úÖ {package} installed\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Failed to install {package}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n",
    "print(\"‚ö†Ô∏è  If this is the first install, please RESTART THE KERNEL:\")\n",
    "print(\"   Jupyter menu: Kernel ‚Üí Restart Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c5a29f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Environment and logging\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Load environment variables from .env file\u001b[39;00m\n\u001b[32m     19\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to path so we can import modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Calculate the project paths dynamically\n",
    "# This notebook is in: notebooks/ folder\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "orchestrator_path = os.path.join(project_root, 'orchestrator')\n",
    "\n",
    "# Add paths for both local and Docker environments\n",
    "sys.path.insert(0, orchestrator_path)\n",
    "sys.path.insert(0, project_root)\n",
    "sys.path.insert(0, '/app')  # For Docker environment\n",
    "\n",
    "print(f\"üìÅ Python paths added:\")\n",
    "print(f\"   Project Root: {project_root}\")\n",
    "print(f\"   Orchestrator: {orchestrator_path}\")\n",
    "\n",
    "# Verify orchestrator path exists\n",
    "if os.path.exists(orchestrator_path):\n",
    "    print(f\"   ‚úÖ Orchestrator directory found\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Orchestrator directory NOT found at: {orchestrator_path}\")\n",
    "\n",
    "# Core Python libraries\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Snowflake libraries\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Environment and logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to import custom logger with fallback\n",
    "try:\n",
    "    from utils.logging import get_logger\n",
    "    logger = get_logger(__name__)\n",
    "    print(f\"   ‚úÖ Using custom structlog logger\")\n",
    "except ImportError as e:\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    print(f\"   ‚ö†Ô∏è  Using standard logging (utils.logging not found)\")\n",
    "    print(f\"   Error details: {e}\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(f\"   Python version: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb2323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AnalystResponse created!\n",
      "   Query: What is the average open rate?\n",
      "   SQL: SELECT AVG(OPEN_RATE) FROM VW_SFMC_EMAIL_PERFORMANCE\n",
      "   Results: [{'AVG_OPEN_RATE': 22.5}]\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class AnalystResponse:\n",
    "    \"\"\"\n",
    "    Container for Cortex Analyst responses.\n",
    "    \n",
    "    Attributes:\n",
    "        query (str): The natural language question\n",
    "        sql (str): Generated SQL query\n",
    "        results (List[Dict]): Query results as list of dictionaries\n",
    "        metadata (Dict): Additional information (row count, execution time)\n",
    "        error (str): Error message if something went wrong\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    sql: Optional[str] = None\n",
    "    results: Optional[List[Dict[str, Any]]] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary (useful for JSON APIs)\"\"\"\n",
    "        return {\n",
    "            \"query\": self.query,\n",
    "            \"sql\": self.sql,\n",
    "            \"results\": self.results,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"error\": self.error\n",
    "        }\n",
    "\n",
    "# Test it out!\n",
    "sample_response = AnalystResponse(\n",
    "    query=\"What is the average open rate?\",\n",
    "    sql=\"SELECT AVG(OPEN_RATE) FROM VW_SFMC_EMAIL_PERFORMANCE\",\n",
    "    results=[{\"AVG_OPEN_RATE\": 22.5}],\n",
    "    metadata={\"row_count\": 1}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AnalystResponse created!\")\n",
    "print(f\"   Query: {sample_response.query}\")\n",
    "print(f\"   SQL: {sample_response.sql}\")\n",
    "print(f\"   Results: {sample_response.results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ffcb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to import CortexAnalyst: No module named 'services'\n",
      "\n",
      "üí° Troubleshooting:\n",
      "   1. Make sure you ran Cell 2 (path setup)\n",
      "   2. Check that orchestrator/services/cortex_analyst.py exists\n",
      "   3. Current sys.path: ['/app', '/app', '/app']\n"
     ]
    }
   ],
   "source": [
    "# Import the CortexAnalyst service class\n",
    "try:\n",
    "    from services.cortex_analyst import CortexAnalyst\n",
    "    print(\"‚úÖ CortexAnalyst class imported successfully!\")\n",
    "    print(\"   Ready to create instances and query Snowflake\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import CortexAnalyst: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Make sure you ran Cell 2 (path setup)\")\n",
    "    print(\"   2. Check that orchestrator/services/cortex_analyst.py exists\")\n",
    "    print(f\"   3. Current sys.path: {sys.path[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de9adb",
   "metadata": {},
   "source": [
    "## üîß Import CortexAnalyst Service\n",
    "\n",
    "Now let's import the complete `CortexAnalyst` class from the services module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfdae92a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CortexAnalyst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create analyst instance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mCortexAnalyst\u001b[49m() \u001b[38;5;28;01mas\u001b[39;00m analyst:\n\u001b[32m      3\u001b[39m     verification = analyst.verify_semantic_model()\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verification[\u001b[33m'\u001b[39m\u001b[33mexists\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[31mNameError\u001b[39m: name 'CortexAnalyst' is not defined"
     ]
    }
   ],
   "source": [
    "# Create analyst instance\n",
    "with CortexAnalyst() as analyst:\n",
    "    verification = analyst.verify_semantic_model()\n",
    "    \n",
    "    if verification['exists']:\n",
    "        print(\"‚úÖ Semantic Model Found!\")\n",
    "        print(f\"   File: {verification['file_name']}\")\n",
    "        print(f\"   Size: {verification['file_size']:,} bytes ({verification['file_size']/1024:.1f} KB)\")\n",
    "        print(f\"   Modified: {verification['last_modified']}\")\n",
    "        print(f\"   Stage: {verification['stage_path']}\")\n",
    "    else:\n",
    "        print(\"‚ùå Semantic Model NOT Found\")\n",
    "        print(f\"   Error: {verification.get('error', 'Unknown')}\")\n",
    "        print(\"\\nüí° Make sure you ran: python scripts/deploy_semantic_model.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9febdf",
   "metadata": {},
   "source": [
    "## üéì Summary: What You Learned\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "‚úÖ **Python OOP Concepts**\n",
    "- Classes and objects  \n",
    "- Instance methods and attributes\n",
    "- Context managers (`with` statement)\n",
    "- Type hints and dataclasses\n",
    "\n",
    "‚úÖ **Snowflake Integration**\n",
    "- Connecting with Snowpark\n",
    "- Executing SQL queries\n",
    "- Handling results\n",
    "\n",
    "‚úÖ **Service Design Patterns**\n",
    "- Lazy loading (efficient resource usage)\n",
    "- Error handling and logging\n",
    "- Structured responses\n",
    "\n",
    "‚úÖ **Production Best Practices**\n",
    "- Environment-based configuration\n",
    "- Comprehensive logging\n",
    "- Clean code with documentation\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Practice More**: Try different questions in the exercise cell above  \n",
    "2. **Build Other Services**: Apply this pattern to `cortex_complete.py`, `cortex_search.py`\n",
    "3. **Enhance Features**: Add caching, retry logic, rate limiting\n",
    "4. **Integration**: Use in your FastAPI endpoints\n",
    "5. **Testing**: Write pytest tests for edge cases\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [Snowflake Cortex Documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex)\n",
    "- [CORTEX_ANALYST_LEARNING_GUIDE.md](../orchestrator/services/CORTEX_ANALYST_LEARNING_GUIDE.md)\n",
    "- [Python Dataclasses](https://docs.python.org/3/library/dataclasses.html)\n",
    "- [Structlog](https://www.structlog.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! üéâ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèãÔ∏è Exercise: Write your own question!\n",
    "\n",
    "with CortexAnalyst() as analyst:\n",
    "    # TODO: Change this question to something you want to know!\n",
    "    my_question = \"CHANGE THIS TO YOUR QUESTION\"\n",
    "    \n",
    "    response = analyst.send_message(my_question)\n",
    "    \n",
    "    if response.error:\n",
    "        print(f\"‚ùå Error: {response.error}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Question: {response.query}\")\n",
    "        print(f\"\\nüìä SQL: {response.sql}\")\n",
    "        print(f\"\\nüìà Results:\")\n",
    "        for i, row in enumerate(response.results[:10], 1):\n",
    "            print(f\"   {i}. {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d189af6",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise: Ask Your Own Question\n",
    "\n",
    "**Your Turn!** Try asking different questions about your email data.\n",
    "\n",
    "**Example Questions:**\n",
    "- \"What was the total emails sent last month?\"\n",
    "- \"Show me click rate by market\"\n",
    "- \"Which campaigns had bounce rate above 5%?\"\n",
    "- \"What is the average open rate by business unit?\"\n",
    "\n",
    "**Instructions:**\n",
    "1. Change the `my_question` variable below\n",
    "2. Run the cell\n",
    "3. See if Cortex Analyst can answer it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57966a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CortexAnalyst() as analyst:\n",
    "    # Ask a question in natural language\n",
    "    question = \"What is the average open rate?\"\n",
    "    \n",
    "    print(f\"ü§î Asking: '{question}'\")\n",
    "    print(\"   Processing...\")\n",
    "    \n",
    "    response = analyst.send_message(question)\n",
    "    \n",
    "    if response.error:\n",
    "        print(f\"\\n‚ö†Ô∏è  Query Failed (Expected if Cortex Analyst not enabled)\")\n",
    "        print(f\"   Error: {response.error}\")\n",
    "        print(\"\\nüí° To enable Cortex Analyst:\")\n",
    "        print(\"   1. Contact Snowflake support or your account admin\")\n",
    "        print(\"   2. Request 'Cortex Analyst' feature activation\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Query Successful!\")\n",
    "        print(f\"\\nüìù Question: {response.query}\")\n",
    "        print(f\"\\nüîç Generated SQL:\")\n",
    "        print(f\"   {response.sql}\")\n",
    "        print(f\"\\nüìä Results:\")\n",
    "        for i, row in enumerate(response.results[:5], 1):  # First 5 rows\n",
    "            print(f\"   {i}. {row}\")\n",
    "        print(f\"\\n‚ÑπÔ∏è  Metadata: {response.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cd727",
   "metadata": {},
   "source": [
    "## üß™ Test 3: Try Cortex Analyst (Natural Language Query)\n",
    "\n",
    "Now let's try asking a question in natural language!\n",
    "\n",
    "**Note:** This requires Cortex Analyst to be enabled in your Snowflake account. If not enabled yet, you'll see an error message (that's expected!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c47e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with CortexAnalyst() as analyst:\n",
    "    try:\n",
    "        # Simple count query\n",
    "        sql = \"SELECT COUNT(*) AS ROW_COUNT FROM VW_SFMC_EMAIL_PERFORMANCE LIMIT 1\"\n",
    "        results = analyst._execute_sql(sql)\n",
    "        \n",
    "        print(\"‚úÖ SQL Execution Test Passed!\")\n",
    "        print(f\"   Rows in VW_SFMC_EMAIL_PERFORMANCE: {results[0]['ROW_COUNT']:,}\")\n",
    "        \n",
    "        # Get sample data\n",
    "        sample_sql = \"SELECT MARKET, OPEN_RATE, CLICK_RATE FROM VW_SFMC_EMAIL_PERFORMANCE LIMIT 5\"\n",
    "        sample_data = analyst._execute_sql(sample_sql)\n",
    "        \n",
    "        print(\"\\nüìä Sample Data:\")\n",
    "        for i, row in enumerate(sample_data, 1):\n",
    "            print(f\"   {i}. Market: {row['MARKET']}, Open Rate: {row['OPEN_RATE']}%, Click Rate: {row['CLICK_RATE']}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SQL Execution Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb435902",
   "metadata": {},
   "source": [
    "## üß™ Test 2: Execute Simple SQL Query\n",
    "\n",
    "Before trying Cortex Analyst, let's test basic SQL execution against your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8631f64",
   "metadata": {},
   "source": [
    "## üß™ Test 1: Verify Semantic Model\n",
    "\n",
    "Let's verify your semantic model is deployed correctly in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3df834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the complete CortexAnalyst class\n",
    "from services.cortex_analyst import CortexAnalyst\n",
    "\n",
    "# Create an instance\n",
    "analyst = CortexAnalyst()\n",
    "\n",
    "print(\"‚úÖ CortexAnalyst instance created!\")\n",
    "print(f\"   Database: {analyst.database}\")\n",
    "print(f\"   Schema: {analyst.schema}\")\n",
    "print(f\"   Semantic Model: @{analyst.stage_name}/{analyst.semantic_model_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f1e7c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ CortexAnalyst Class: Complete Implementation\n",
    "\n",
    "Now let's import the complete CortexAnalyst class from our service module.\n",
    "\n",
    "This class includes:\n",
    "- Snowflake connection management\n",
    "- Cortex Analyst API calls\n",
    "- Error handling and logging\n",
    "- Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7b2f5",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Data Models: AnalystResponse\n",
    "\n",
    "Before we build the service, let's create a data structure to hold responses from Cortex Analyst.\n",
    "\n",
    "**Why dataclasses?**\n",
    "- Clean, readable code\n",
    "- Type hints for better error checking\n",
    "- Built-in methods like `__repr__`\n",
    "- Less boilerplate than regular classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaaf67",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries\n",
    "\n",
    "First, we need to import all the Python libraries we'll use:\n",
    "- **snowflake.snowpark**: For connecting to Snowflake\n",
    "- **dotenv**: For loading environment variables\n",
    "- **dataclasses**: For creating data structures\n",
    "- **json**: For parsing JSON responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
