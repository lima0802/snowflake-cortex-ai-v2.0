{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888537f4",
   "metadata": {},
   "source": [
    "# üìà Cortex ML Interactive Tutorial\n",
    "## Learn by Doing: Time Series Forecasting & Anomaly Detection\n",
    "\n",
    "**Author:** Li Ma  \n",
    "**Date:** February 24, 2026  \n",
    "**Project:** DIA v2.0 - Direct Marketing Analytics Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "This interactive notebook teaches you how to:\n",
    "1. ‚úÖ Forecast future metrics (email volume, open rates, revenue)\n",
    "2. ‚úÖ Detect anomalies in time series data\n",
    "3. ‚úÖ Understand confidence intervals\n",
    "4. ‚úÖ Monitor data quality and system health\n",
    "5. ‚úÖ Build predictive analytics pipelines\n",
    "\n",
    "## üéØ Prerequisites\n",
    "\n",
    "- Docker containers running (`docker-compose up`)\n",
    "- Snowflake credentials configured in `.env` file\n",
    "- Time series data in Snowflake (minimum 14 days)\n",
    "\n",
    "## üß† What is Cortex ML?\n",
    "\n",
    "**Cortex ML** provides machine learning functions for time series data:\n",
    "\n",
    "### 1. FORECAST() - Predict Future Values\n",
    "- Predict next week's email volume\n",
    "- Forecast expected open rates\n",
    "- Estimate future revenue\n",
    "- Capacity planning\n",
    "\n",
    "### 2. ANOMALY_DETECTION() - Find Unusual Patterns\n",
    "- Detect sudden bounce rate spikes\n",
    "- Identify data quality issues\n",
    "- Alert on system anomalies\n",
    "- Monitor KPI deviations\n",
    "\n",
    "**Use Cases:**\n",
    "- Performance forecasting\n",
    "- Capacity planning\n",
    "- Quality monitoring\n",
    "- Trend analysis\n",
    "- Alert systems\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Data Requirements\n",
    "\n",
    "For accurate ML predictions:\n",
    "- ‚úÖ **Time series data** (date/timestamp column)\n",
    "- ‚úÖ **Numeric metrics** (values to predict)\n",
    "- ‚úÖ **Minimum 14 days** of historical data\n",
    "- ‚úÖ **Regular intervals** (daily, hourly, etc.)\n",
    "- ‚úÖ **No missing dates** (fill gaps with 0 or interpolate)\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** Run each cell with `Shift + Enter` and experiment with your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254dfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for this notebook\n",
    "# Run this cell once to install dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'structlog',\n",
    "    'python-dotenv',\n",
    "    'snowflake-snowpark-python',\n",
    "    'pandas',\n",
    "    'matplotlib'\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing required packages...\")\n",
    "for package in packages:\n",
    "    print(f\"   Installing {package}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"   ‚úÖ {package} installed\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Failed to install {package}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n",
    "print(\"‚ö†Ô∏è  If this is the first install, please RESTART THE KERNEL:\")\n",
    "print(\"   Jupyter menu: Kernel ‚Üí Restart Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Python paths and import libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Calculate the project paths dynamically\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "orchestrator_path = os.path.join(project_root, 'orchestrator')\n",
    "\n",
    "# Add paths for both local and Docker environments\n",
    "sys.path.insert(0, orchestrator_path)\n",
    "sys.path.insert(0, project_root)\n",
    "sys.path.insert(0, '/app')\n",
    "\n",
    "print(f\"üìÅ Python paths added:\")\n",
    "print(f\"   Project Root: {project_root}\")\n",
    "print(f\"   Orchestrator: {orchestrator_path}\")\n",
    "\n",
    "# Verify orchestrator path exists\n",
    "if os.path.exists(orchestrator_path):\n",
    "    print(f\"   ‚úÖ Orchestrator directory found\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Orchestrator directory NOT found at: {orchestrator_path}\")\n",
    "\n",
    "# Core Python libraries\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Snowflake libraries\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Environment and logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to import custom logger with fallback\n",
    "try:\n",
    "    from utils.logging import get_logger\n",
    "    logger = get_logger(__name__)\n",
    "    print(f\"   ‚úÖ Using custom structlog logger\")\n",
    "except ImportError as e:\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    print(f\"   ‚ö†Ô∏è  Using standard logging (utils.logging not found)\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(f\"   Python version: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8dd1f",
   "metadata": {},
   "source": [
    "## üì¶ Understanding the Response Data Models\n",
    "\n",
    "The ML service uses these data structures for predictions and anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ForecastResult:\n",
    "    \"\"\"\n",
    "    Single forecast prediction with confidence interval.\n",
    "    \n",
    "    Attributes:\n",
    "        timestamp: Date/time of prediction\n",
    "        forecast: Predicted value\n",
    "        lower_bound: Lower confidence interval (pessimistic)\n",
    "        upper_bound: Upper confidence interval (optimistic)\n",
    "    \"\"\"\n",
    "    timestamp: Any\n",
    "    forecast: float\n",
    "    lower_bound: Optional[float] = None\n",
    "    upper_bound: Optional[float] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ForecastResponse:\n",
    "    \"\"\"\n",
    "    Complete forecast response with all predictions.\n",
    "    \n",
    "    Attributes:\n",
    "        table: Source data table\n",
    "        metric: Column being predicted\n",
    "        forecasts: List of predictions\n",
    "        metadata: Model info (algorithm, accuracy, etc.)\n",
    "        error: Error message if something went wrong\n",
    "    \"\"\"\n",
    "    table: str\n",
    "    metric: str\n",
    "    forecasts: Optional[List[ForecastResult]] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AnomalyResult:\n",
    "    \"\"\"\n",
    "    Single anomaly detection result.\n",
    "    \n",
    "    Attributes:\n",
    "        timestamp: Date/time of data point\n",
    "        value: Actual observed value\n",
    "        expected: Expected value based on patterns\n",
    "        is_anomaly: True if unusual, False if normal\n",
    "        score: Anomaly score (higher = more unusual)\n",
    "    \"\"\"\n",
    "    timestamp: Any\n",
    "    value: float\n",
    "    expected: Optional[float] = None\n",
    "    is_anomaly: bool = False\n",
    "    score: Optional[float] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AnomalyResponse:\n",
    "    \"\"\"\n",
    "    Complete anomaly detection response.\n",
    "    \n",
    "    Attributes:\n",
    "        table: Source data table\n",
    "        metric: Column being analyzed\n",
    "        anomalies: List of all data points (marked if anomaly)\n",
    "        metadata: Detection info (threshold, sensitivity, etc.)\n",
    "        error: Error message if something went wrong\n",
    "    \"\"\"\n",
    "    table: str\n",
    "    metric: str\n",
    "    anomalies: Optional[List[AnomalyResult]] = None\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[str] = None\n",
    "    \n",
    "    @property\n",
    "    def anomaly_count(self) -> int:\n",
    "        \"\"\"Count how many anomalies were found\"\"\"\n",
    "        if not self.anomalies:\n",
    "            return 0\n",
    "        return sum(1 for a in self.anomalies if a.is_anomaly)\n",
    "    \n",
    "    @property\n",
    "    def has_anomalies(self) -> bool:\n",
    "        \"\"\"Check if any anomalies were found\"\"\"\n",
    "        return self.anomaly_count > 0\n",
    "\n",
    "\n",
    "# Test it out!\n",
    "sample_forecast = ForecastResult(\n",
    "    timestamp=\"2026-03-01\",\n",
    "    forecast=25000.0,\n",
    "    lower_bound=23000.0,\n",
    "    upper_bound=27000.0\n",
    ")\n",
    "\n",
    "sample_anomaly = AnomalyResult(\n",
    "    timestamp=\"2026-02-20\",\n",
    "    value=15.2,\n",
    "    expected=8.5,\n",
    "    is_anomaly=True,\n",
    "    score=0.95\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ML data models created!\")\n",
    "print(f\"\\nüìà Forecast Example:\")\n",
    "print(f\"   Date: {sample_forecast.timestamp}\")\n",
    "print(f\"   Predicted: {sample_forecast.forecast:,.0f}\")\n",
    "print(f\"   Range: {sample_forecast.lower_bound:,.0f} - {sample_forecast.upper_bound:,.0f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Anomaly Example:\")\n",
    "print(f\"   Date: {sample_anomaly.timestamp}\")\n",
    "print(f\"   Actual: {sample_anomaly.value}\")\n",
    "print(f\"   Expected: {sample_anomaly.expected}\")\n",
    "print(f\"   Is Anomaly: {sample_anomaly.is_anomaly}\")\n",
    "print(f\"   Score: {sample_anomaly.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dbb8c",
   "metadata": {},
   "source": [
    "## üîß Import CortexML Service\n",
    "\n",
    "Now let's import the `CortexML` class from the services module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724756a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CortexML service class\n",
    "try:\n",
    "    from services.cortex_ml import CortexML\n",
    "    print(\"‚úÖ CortexML class imported successfully!\")\n",
    "    print(\"   Ready to forecast and detect anomalies\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import CortexML: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Make sure you ran Cell 2 (path setup)\")\n",
    "    print(\"   2. Check that orchestrator/services/cortex_ml.py exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadc963",
   "metadata": {},
   "source": [
    "## üìà Example 1: Forecast Future Metrics\n",
    "\n",
    "Predict future email volume for the next 30 days.\n",
    "\n",
    "**‚ö†Ô∏è Note:** Update table and column names to match your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast email volume for next 30 days\n",
    "TABLE_NAME = \"VW_SFMC_EMAIL_PERFORMANCE\"  # Your table name\n",
    "TIMESTAMP_COL = \"SEND_DATE\"                # Date column\n",
    "TARGET_COL = \"EMAILS_SENT\"                 # Metric to predict\n",
    "\n",
    "try:\n",
    "    ml = CortexML()\n",
    "    \n",
    "    print(f\"üìà Forecasting {TARGET_COL} from {TABLE_NAME}...\")\n",
    "    print(f\"   Time column: {TIMESTAMP_COL}\")\n",
    "    print(f\"   Forecasting: 30 days ahead\\n\")\n",
    "    \n",
    "    forecast_response = ml.forecast(\n",
    "        table=TABLE_NAME,\n",
    "        timestamp_col=TIMESTAMP_COL,\n",
    "        target_col=TARGET_COL,\n",
    "        periods=30  # Predict next 30 days\n",
    "    )\n",
    "    \n",
    "    if forecast_response.error:\n",
    "        print(f\"‚ùå Error: {forecast_response.error}\")\n",
    "        print(\"\\nüí° Common issues:\")\n",
    "        print(\"   ‚Ä¢ Less than 14 days of historical data\")\n",
    "        print(\"   ‚Ä¢ Missing dates in time series\")\n",
    "        print(\"   ‚Ä¢ Table/column names don't exist\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Forecast generated: {len(forecast_response.forecasts)} predictions\\n\")\n",
    "        \n",
    "        # Show first 7 days\n",
    "        print(\"üìä First 7 Days Forecast:\")\n",
    "        print(\"-\" * 70)\n",
    "        for forecast in forecast_response.forecasts[:7]:\n",
    "            print(f\"{forecast.timestamp}: {forecast.forecast:,.0f}\")\n",
    "            print(f\"   Range: {forecast.lower_bound:,.0f} - {forecast.upper_bound:,.0f}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_predicted = sum(f.forecast for f in forecast_response.forecasts)\n",
    "        print(f\"\\nüìä 30-Day Summary:\")\n",
    "        print(f\"   Total Predicted: {total_predicted:,.0f}\")\n",
    "        print(f\"   Daily Average: {total_predicted/30:,.0f}\")\n",
    "        print(f\"   Algorithm: {forecast_response.metadata.get('algorithm', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Forecast failed: {e}\")\n",
    "    print(\"\\nüí° Make sure:\")\n",
    "    print(\"   1. Table exists and has time series data\")\n",
    "    print(\"   2. Column names are correct\")\n",
    "    print(\"   3. Minimum 14 days of historical data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9238aa",
   "metadata": {},
   "source": [
    "## üìä Visualize the Forecast\n",
    "\n",
    "Let's plot the forecast to see the trend visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast (if forecast was successful)\n",
    "try:\n",
    "    if 'forecast_response' in locals() and not forecast_response.error:\n",
    "        # Extract data for plotting\n",
    "        dates = [f.timestamp for f in forecast_response.forecasts]\n",
    "        predictions = [f.forecast for f in forecast_response.forecasts]\n",
    "        lower = [f.lower_bound for f in forecast_response.forecasts]\n",
    "        upper = [f.upper_bound for f in forecast_response.forecasts]\n",
    "        \n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(dates, predictions, 'b-', linewidth=2, label='Forecast')\n",
    "        plt.fill_between(dates, lower, upper, alpha=0.3, label='Confidence Interval')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(TARGET_COL)\n",
    "        plt.title(f'30-Day Forecast: {TARGET_COL}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Forecast visualization complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No forecast data to visualize\")\n",
    "        print(\"   Run the forecast cell first!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Visualization error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab75935",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è  Example 2: Detect Anomalies\n",
    "\n",
    "Find unusual patterns in bounce rates or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf15cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies in bounce rate\n",
    "TARGET_COL_ANOMALY = \"BOUNCE_RATE\"  # Metric to check for anomalies\n",
    "\n",
    "try:\n",
    "    ml = CortexML()\n",
    "    \n",
    "    print(f\"üîç Detecting anomalies in {TARGET_COL_ANOMALY}...\")\n",
    "    print(f\"   Table: {TABLE_NAME}\")\n",
    "    print(f\"   Sensitivity: 0.95 (95% confidence)\\n\")\n",
    "    \n",
    "    anomaly_response = ml.detect_anomalies(\n",
    "        table=TABLE_NAME,\n",
    "        timestamp_col=TIMESTAMP_COL,\n",
    "        target_col=TARGET_COL_ANOMALY,\n",
    "        sensitivity=0.95  # 0.9 to 0.99 (higher = more sensitive)\n",
    "    )\n",
    "    \n",
    "    if anomaly_response.error:\n",
    "        print(f\"‚ùå Error: {anomaly_response.error}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Anomaly detection complete!\\n\")\n",
    "        \n",
    "        if anomaly_response.has_anomalies:\n",
    "            print(f\"‚ö†Ô∏è  Found {anomaly_response.anomaly_count} anomalies!\\n\")\n",
    "            print(\"üìä Anomalies Detected:\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for anomaly in anomaly_response.anomalies:\n",
    "                if anomaly.is_anomaly:\n",
    "                    print(f\"üî¥ {anomaly.timestamp}\")\n",
    "                    print(f\"   Actual: {anomaly.value:.2f}\")\n",
    "                    print(f\"   Expected: {anomaly.expected:.2f}\")\n",
    "                    print(f\"   Deviation: {abs(anomaly.value - anomaly.expected):.2f}\")\n",
    "                    print(f\"   Score: {anomaly.score:.3f}\")\n",
    "                    print()\n",
    "        else:\n",
    "            print(f\"‚úÖ No anomalies detected - all values are normal!\")\n",
    "            print(f\"   Analyzed {len(anomaly_response.anomalies)} data points\")\n",
    "        \n",
    "        print(f\"\\nüìä Detection Settings:\")\n",
    "        print(f\"   Sensitivity: {anomaly_response.metadata.get('sensitivity', 0.95)}\")\n",
    "        print(f\"   Algorithm: {anomaly_response.metadata.get('algorithm', 'Statistical')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Anomaly detection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684157ed",
   "metadata": {},
   "source": [
    "## üìâ Visualize Anomalies\n",
    "\n",
    "Plot the metric with anomalies highlighted in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74023c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalies (if detection was successful)\n",
    "try:\n",
    "    if 'anomaly_response' in locals() and not anomaly_response.error:\n",
    "        # Extract data\n",
    "        dates = [a.timestamp for a in anomaly_response.anomalies]\n",
    "        values = [a.value for a in anomaly_response.anomalies]\n",
    "        expected = [a.expected for a in anomaly_response.anomalies]\n",
    "        is_anomaly = [a.is_anomaly for a in anomaly_response.anomalies]\n",
    "        \n",
    "        # Split into normal and anomaly points\n",
    "        normal_dates = [d for d, is_anom in zip(dates, is_anomaly) if not is_anom]\n",
    "        normal_values = [v for v, is_anom in zip(values, is_anomaly) if not is_anom]\n",
    "        anomaly_dates = [d for d, is_anom in zip(dates, is_anomaly) if is_anom]\n",
    "        anomaly_values = [v for v, is_anom in zip(values, is_anomaly) if is_anom]\n",
    "        \n",
    "        # Create plot\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(dates, expected, 'g--', alpha=0.5, label='Expected', linewidth=1)\n",
    "        plt.scatter(normal_dates, normal_values, c='blue', alpha=0.6, label='Normal', s=30)\n",
    "        plt.scatter(anomaly_dates, anomaly_values, c='red', alpha=0.8, label='Anomaly', s=100, marker='x', linewidths=3)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(TARGET_COL_ANOMALY)\n",
    "        plt.title(f'Anomaly Detection: {TARGET_COL_ANOMALY}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Anomaly visualization complete!\")\n",
    "        print(f\"   üîµ Blue dots: Normal values ({len(normal_dates)} points)\")\n",
    "        print(f\"   üî¥ Red X: Anomalies ({len(anomaly_dates)} points)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No anomaly data to visualize\")\n",
    "        print(\"   Run the anomaly detection cell first!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Visualization error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768d461",
   "metadata": {},
   "source": [
    "## üéØ Example 3: Forecast Multiple Metrics\n",
    "\n",
    "Compare forecasts for different metrics side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be11774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast multiple metrics\n",
    "metrics_to_forecast = [\n",
    "    \"OPEN_RATE\",\n",
    "    \"CLICK_RATE\",\n",
    "    \"BOUNCE_RATE\"\n",
    "]\n",
    "\n",
    "forecast_results = {}\n",
    "\n",
    "print(\"üìà Forecasting Multiple Metrics:\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    ml = CortexML()\n",
    "    \n",
    "    for metric in metrics_to_forecast:\n",
    "        print(f\"\\nüîÑ Forecasting {metric}...\")\n",
    "        \n",
    "        try:\n",
    "            response = ml.forecast(\n",
    "                table=TABLE_NAME,\n",
    "                timestamp_col=TIMESTAMP_COL,\n",
    "                target_col=metric,\n",
    "                periods=7  # Next 7 days\n",
    "            )\n",
    "            \n",
    "            if response.error:\n",
    "                print(f\"   ‚ùå Error: {response.error}\")\n",
    "            else:\n",
    "                forecast_results[metric] = response\n",
    "                avg_forecast = sum(f.forecast for f in response.forecasts) / len(response.forecasts)\n",
    "                print(f\"   ‚úÖ 7-day average forecast: {avg_forecast:.2f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"\\nüìä Summary:\")\n",
    "    for metric, response in forecast_results.items():\n",
    "        avg = sum(f.forecast for f in response.forecasts) / len(response.forecasts)\n",
    "        print(f\"   {metric}: {avg:.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Multiple forecast failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48139f9d",
   "metadata": {},
   "source": [
    "## üîî Example 4: Alert System\n",
    "\n",
    "Build an anomaly alert system that monitors metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830115bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly alert system\n",
    "def check_for_alerts(table: str, metrics: List[str], sensitivity: float = 0.95):\n",
    "    \"\"\"\n",
    "    Monitor multiple metrics and alert on anomalies.\n",
    "    \n",
    "    Args:\n",
    "        table: Table to monitor\n",
    "        metrics: List of metric columns to check\n",
    "        sensitivity: Anomaly detection threshold\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of alerts by metric\n",
    "    \"\"\"\n",
    "    ml = CortexML()\n",
    "    alerts = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        try:\n",
    "            response = ml.detect_anomalies(\n",
    "                table=table,\n",
    "                timestamp_col=TIMESTAMP_COL,\n",
    "                target_col=metric,\n",
    "                sensitivity=sensitivity\n",
    "            )\n",
    "            \n",
    "            if not response.error and response.has_anomalies:\n",
    "                alerts[metric] = [\n",
    "                    a for a in response.anomalies if a.is_anomaly\n",
    "                ]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error checking {metric}: {e}\")\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "\n",
    "# Run alert check\n",
    "print(\"üîî Running Anomaly Alert System...\\n\")\n",
    "\n",
    "alert_metrics = [\"BOUNCE_RATE\", \"UNSUBSCRIBE_RATE\"]\n",
    "\n",
    "try:\n",
    "    alerts = check_for_alerts(TABLE_NAME, alert_metrics, sensitivity=0.95)\n",
    "    \n",
    "    if alerts:\n",
    "        print(f\"‚ö†Ô∏è  ALERTS DETECTED!\\n\")\n",
    "        for metric, anomalies in alerts.items():\n",
    "            print(f\"üî¥ {metric}: {len(anomalies)} anomalies\")\n",
    "            for a in anomalies[:3]:  # Show first 3\n",
    "                print(f\"   ‚Ä¢ {a.timestamp}: {a.value:.2f} (expected {a.expected:.2f})\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"‚úÖ All systems normal - no anomalies detected!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Alert system error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2cf53",
   "metadata": {},
   "source": [
    "## üéì Summary: What You Learned\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "‚úÖ **Cortex ML Fundamentals**\n",
    "- Time series forecasting\n",
    "- Anomaly detection\n",
    "- Confidence intervals\n",
    "- Sensitivity tuning\n",
    "\n",
    "‚úÖ **Practical Applications**\n",
    "- Forecast email metrics\n",
    "- Detect unusual patterns\n",
    "- Monitor multiple KPIs\n",
    "- Build alert systems\n",
    "\n",
    "‚úÖ **Data Visualization**\n",
    "- Plot forecasts with confidence intervals\n",
    "- Highlight anomalies\n",
    "- Compare multiple metrics\n",
    "\n",
    "‚úÖ **Python Skills**\n",
    "- Dataclasses for structured data\n",
    "- Matplotlib for visualization\n",
    "- List comprehensions\n",
    "- Error handling\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Try These Experiments:**\n",
    "1. Forecast different time horizons (7, 14, 30 days)\n",
    "2. Compare sensitivity levels (0.90, 0.95, 0.99)\n",
    "3. Monitor daily vs weekly aggregations\n",
    "4. Build automated alert emails\n",
    "\n",
    "**Advanced Use Cases:**\n",
    "\n",
    "### 1. Capacity Planning\n",
    "```python\n",
    "# Predict infrastructure needs\n",
    "server_forecast = ml.forecast(\n",
    "    table=\"SYSTEM_METRICS\",\n",
    "    timestamp_col=\"HOUR\",\n",
    "    target_col=\"API_REQUESTS\",\n",
    "    periods=168  # Next week (hourly)\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. Performance Monitoring\n",
    "```python\n",
    "# Track KPI trends\n",
    "for metric in [\"OPEN_RATE\", \"CTR\", \"CONVERSION_RATE\"]:\n",
    "    forecast = ml.forecast(\n",
    "        table=\"DAILY_METRICS\",\n",
    "        timestamp_col=\"DATE\",\n",
    "        target_col=metric,\n",
    "        periods=30\n",
    "    )\n",
    "    # Alert if forecast < target\n",
    "```\n",
    "\n",
    "### 3. Data Quality Checks\n",
    "```python\n",
    "# Detect data issues\n",
    "quality_check = ml.detect_anomalies(\n",
    "    table=\"RAW_DATA\",\n",
    "    timestamp_col=\"LOAD_DATE\",\n",
    "    target_col=\"NULL_COUNT\",\n",
    "    sensitivity=0.99\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Related Resources\n",
    "\n",
    "- **Documentation:** `guides/02_STEP_2.1_CORTEX_SERVICES.md`\n",
    "- **Service Code:** `orchestrator/services/cortex_ml.py`\n",
    "- **Other Notebooks:**\n",
    "  - `cortex_analyst_interactive.ipynb` - SQL generation\n",
    "  - `cortex_complete_interactive.ipynb` - Text generation\n",
    "  - `cortex_search_interactive.ipynb` - Semantic search\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Key Concepts\n",
    "\n",
    "### Confidence Intervals\n",
    "\n",
    "Forecasts include uncertainty ranges:\n",
    "- **Forecast:** Most likely value\n",
    "- **Lower Bound:** Pessimistic estimate (90% confident actual will be above this)\n",
    "- **Upper Bound:** Optimistic estimate (90% confident actual will be below this)\n",
    "\n",
    "Example: Forecast = 1000, Range = 800-1200\n",
    "- Most likely: 1000 emails\n",
    "- Could be as low as: 800\n",
    "- Could be as high as: 1200\n",
    "\n",
    "### Anomaly Sensitivity\n",
    "\n",
    "Controls how strict detection is:\n",
    "- **0.90 (90%)**: Only catch obvious anomalies\n",
    "- **0.95 (95%)**: Balanced - good default\n",
    "- **0.99 (99%)**: Very sensitive - catch subtle issues\n",
    "\n",
    "Higher sensitivity = More anomalies detected = More false positives\n",
    "\n",
    "### Time Series Requirements\n",
    "\n",
    "**Good Data:**\n",
    "‚úÖ Daily values for 30+ days\n",
    "‚úÖ No missing dates\n",
    "‚úÖ Consistent intervals\n",
    "\n",
    "**Bad Data:**\n",
    "‚ùå Only 5 days of history\n",
    "‚ùå Gaps in dates (missing weeks)\n",
    "‚ùå Irregular intervals (random dates)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Combining All Cortex Services\n",
    "\n",
    "```python\n",
    "# Complete workflow example\n",
    "def analyze_performance():\n",
    "    # 1. Get historical data (Cortex Analyst)\n",
    "    analyst = CortexAnalyst()\n",
    "    data = analyst.send_message(\"What was daily open rate last 90 days?\")\n",
    "    \n",
    "    # 2. Detect anomalies (Cortex ML)\n",
    "    ml = CortexML()\n",
    "    anomalies = ml.detect_anomalies(\n",
    "        table=\"EMAIL_METRICS\",\n",
    "        timestamp_col=\"DATE\",\n",
    "        target_col=\"OPEN_RATE\"\n",
    "    )\n",
    "    \n",
    "    # 3. Forecast future (Cortex ML)\n",
    "    forecast = ml.forecast(\n",
    "        table=\"EMAIL_METRICS\",\n",
    "        timestamp_col=\"DATE\",\n",
    "        target_col=\"OPEN_RATE\",\n",
    "        periods=30\n",
    "    )\n",
    "    \n",
    "    # 4. Generate insights (Cortex Complete)\n",
    "    llm = CortexComplete()\n",
    "    summary = llm.complete(f\"\"\"\n",
    "    Analyze this performance data:\n",
    "    - Historical: {data.results}\n",
    "    - Anomalies: {anomalies.anomaly_count}\n",
    "    - Forecast: {forecast.forecasts[0].forecast}\n",
    "    \n",
    "    Provide 3 key insights:\n",
    "    \"\"\")\n",
    "    \n",
    "    return summary\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Status:** ‚úÖ Tutorial Complete  \n",
    "**Congratulations!** You've mastered all 4 Cortex services! üéâ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
